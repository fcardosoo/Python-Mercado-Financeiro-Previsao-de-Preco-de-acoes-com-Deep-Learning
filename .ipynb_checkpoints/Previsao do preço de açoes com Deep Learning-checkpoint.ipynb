{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc240e42",
   "metadata": {},
   "source": [
    "# Modelo de DEEP LEARNING baseado na memória de curto prazo - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf57a2",
   "metadata": {},
   "source": [
    "## 1. Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "830a4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy                  as np\n",
    "import pandas                 as pd\n",
    "import yfinance               as yf\n",
    "\n",
    "import matplotlib.pyplot      as plt\n",
    "\n",
    "from datetime                 import datetime\n",
    "from datetime                 import timedelta\n",
    "\n",
    "from sklearn.preprocessing    import MinMaxScaler\n",
    "\n",
    "from keras.models             import Sequential\n",
    "from keras.layers             import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7d79b",
   "metadata": {},
   "source": [
    "## 2. Ativo de interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21fb7973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CMIN.SA: No data found, symbol may be delisted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acao = 'CMIN.SA'\n",
    "\n",
    "inicio = '2014-12-31'\n",
    "final  = '2023-05-26'\n",
    "\n",
    "dados_acao = yf.download(acao, inicio, final)\n",
    "\n",
    "dados_acao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a6c0b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 1), dtype=float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionaremos o valor de fechamento 'Close', ao invés da cotação ajustada 'Adj Close' (mais comunmente encontrada\n",
    "# nos modelos de financças), pois precisamos de uma cotação real;\n",
    "\n",
    "cotacao = dados_acao['Close'].to_numpy().reshape(-1, 1) # reescalando os dados com o numpy\n",
    "cotacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aae00b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tamanho_dados_treinamento = int(len(cotacao) * 0.8)\n",
    "\n",
    "tamanho_dados_treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0476d53c",
   "metadata": {},
   "source": [
    "## 3. Separando os dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "853bec0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Escalar os dados entre 0 e 1\u001b[39;00m\n\u001b[0;32m      3\u001b[0m escalador \u001b[38;5;241m=\u001b[39m MinMaxScaler(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m dados_entre_0_e_1_treinamento \u001b[38;5;241m=\u001b[39m \u001b[43mescalador\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcotacao\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtamanho_dados_treinamento\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m dados_entre_0_e_1_teste \u001b[38;5;241m=\u001b[39m escalador\u001b[38;5;241m.\u001b[39mtransform(cotacao[tamanho_dados_treinamento: , :])\n\u001b[0;32m      9\u001b[0m dados_entre_0_e_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dados_entre_0_e_1_treinamento\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mlen\u001b[39m(dados_entre_0_e_1_treinamento))) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(dados_entre_0_e_1_teste\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(dados_entre_0_e_1_teste)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:427\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:466\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    465\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    474\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "# Escalar os dados entre 0 e 1\n",
    "\n",
    "escalador = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "dados_entre_0_e_1_treinamento = escalador.fit_transform(cotacao[0:tamanho_dados_treinamento, :])\n",
    "\n",
    "dados_entre_0_e_1_teste = escalador.transform(cotacao[tamanho_dados_treinamento: , :])\n",
    "\n",
    "dados_entre_0_e_1 = list(dados_entre_0_e_1_treinamento.reshape(\n",
    "    len(dados_entre_0_e_1_treinamento))) + list(dados_entre_0_e_1_teste.reshape(len(dados_entre_0_e_1_teste)))\n",
    "\n",
    "dados_entre_0_e_1 = np.array(dados_entre_0_e_1).reshape(len(dados_entre_0_e_1), 1)\n",
    "\n",
    "dados_entre_0_e_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98960bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_para_treinamento = dados_entre_0_e_1[0: tamanho_dados_treinamento, :]\n",
    "\n",
    "# dados usados para gerar o resultado\n",
    "treinamento_x = []\n",
    "\n",
    "# cotação real\n",
    "treinamento_y = []\n",
    "\n",
    "for i in range(60, len(dados_para_treinamento)):\n",
    "    \n",
    "    # 60 últimos dias\n",
    "    treinamento_x.append(dados_para_treinamento[i - 60: i, 0])\n",
    "    \n",
    "    # cotação real\n",
    "    treinamento_y.append(dados_para_treinamento[i, 0])\n",
    "    \n",
    "    if i <= 61:\n",
    "        print(treinamento_x)\n",
    "        print(treinamento_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22edee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando as listas em arrays e dando um reshape, pois o modelo necessida dos dados em 3 Dimensões\n",
    "\n",
    "treinamento_x, treinamento_y = np.array(treinamento_x), np.array(treinamento_y)\n",
    "treinamento_x = treinamento_x.reshape(treinamento_x.shape[0], treinamento_x.shape[1], 1)\n",
    "treinamento_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812c2ab",
   "metadata": {},
   "source": [
    "## 4.0 Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "# Modelo com 50 neurônios;\n",
    "# return sequences = True pois usaremos outro LSTM depois;\n",
    "# definir o shape, que no caso são 60 informações para gerar um valor;\n",
    "# adicionar mais neurônios com o dense de 25 e 1\n",
    "\n",
    "modelo.add(LSTM(50, return_sequences=True, input_shape = (treinamento_x.shape[1], 1))) # Modelo de 50 neurônios + return_sequences = True para adicionar mais 50 neurônios\n",
    "modelo.add(LSTM(50, return_sequences=False))\n",
    "modelo.add(Dense(25))\n",
    "modelo.add(Dense(1))\n",
    "\n",
    "treinamento_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5192d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copilando o modelo\n",
    "\n",
    "# A função de Loss é a forma de medir o ERRO do modelo, que nesse caso é classificado como o Erro Médio Quadrátrico que é\n",
    "# usado na Regresão Linear\n",
    "\n",
    "modelo.compile(optimizer = 'adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d78269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora com o modelo copilado e os dados, treinaremos o modelo\n",
    "# batch size -> neste caso o modelo irá otimizar os parâmetros a cada novo dado\n",
    "# epochs -> quantas vezes o algoritmo irá rodar os dados de treinamento\n",
    "\n",
    "modelo.fit(treinamento_x, treinamento_y, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465994e",
   "metadata": {},
   "source": [
    "### 4.1 Modelo de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste = dados_entre_0_e_1[tamanho_dados_treinamento - 60:, :]\n",
    "\n",
    "teste_x = []\n",
    "teste_y = cotacao[tamanho_dados_treinamento: , :]\n",
    "\n",
    "for i in range(60, len(dados_teste)):\n",
    "    teste_x.append(dados_teste[i - 60: i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ebd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "\n",
    "teste_x = np.array(teste_x)\n",
    "teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268f593",
   "metadata": {},
   "source": [
    "### 4.2 Predições do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicoes = modelo.predict(teste_x)\n",
    "\n",
    "# Tirando a escala dos dados\n",
    "predicoes = escalador.inverse_transform(predicoes)\n",
    "\n",
    "predicoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5f711",
   "metadata": {},
   "source": [
    "### 4.3 Erro Médio Quadrático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36077853",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean(predicoes - teste_y) ** 2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o gráfico do modelo\n",
    "\n",
    "treinamento = dados_acao.iloc[:tamanho_dados_treinamento, :]\n",
    "df_teste = pd.DataFrame({'Close': dados_acao['Close'].iloc[tamanho_dados_treinamento:],\n",
    "                        'predicoes': predicoes.reshape(len(predicoes))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o gráfico\n",
    "\n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.title('Modelo')\n",
    "plt.xlabel('Data', fontsize = 20)\n",
    "plt.ylabel('Preço de fechamento', fontsize = 20)\n",
    "plt.plot(treinamento['Close'])\n",
    "plt.plot(df_teste[['Close', 'predicoes']])\n",
    "plt.legend(['Treinamento', 'Real', 'Predições'], loc = 2, prop={'size': '16'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste.sort_index()\n",
    "\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d390e8",
   "metadata": {},
   "source": [
    "### 4.4 Avaliando a acertividade do modelo em prever o direcionamento do ativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056362c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste['variacao_percentual_acao'] = df_teste['Close'].pct_change()\n",
    "df_teste['variacao_percentual_modelo'] = df_teste['predicoes'].pct_change()\n",
    "\n",
    "df_teste = df_teste.dropna()\n",
    "\n",
    "df_teste['var_acao_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_acao'] > 0, True, False)\n",
    "df_teste['var_modelo_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_modelo'] > 0, True, False)\n",
    "\n",
    "df_teste['acertou_o_lado'] = np.where(df_teste['var_acao_maior_menor_que_zero'] == df_teste['var_modelo_maior_menor_que_zero'], True, False)\n",
    "df_teste['variacao_percentual_acao_abs'] = df_teste['variacao_percentual_acao'].abs()\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9421b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acertou_lado = df_teste['acertou_o_lado'].sum()/len(df_teste['acertou_o_lado'])\n",
    "errou_lado = 1 - acertou_lado\n",
    "\n",
    "media_lucro = df_teste.groupby('acertou_o_lado')['variacao_percentual_acao_abs'].mean()\n",
    "\n",
    "exp_mat_lucro = acertou_lado * media_lucro[1] - media_lucro[0] * errou_lado\n",
    "\n",
    "ganho_sobre_perda = media_lucro[1]/media_lucro[0]\n",
    "\n",
    "print(f'O lucro médio foi de \\n{media_lucro.round(4)}')\n",
    "print(f'A relação de Lucro/Perda foi de {ganho_sobre_perda.round(4)}')\n",
    "print(f'O percentual de acerto do lado foi de {acertou_lado.round(4)*100}%')\n",
    "print(f'Expectativa de ganho por dia {exp_mat_lucro.round(4)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b636c8e",
   "metadata": {},
   "source": [
    "### 4.5 Gerando previsão de direção do ativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hoje = datetime.now()\n",
    "\n",
    "if data_hoje.hour > 18: # verificando se o mercado está aberto ou já fechou\n",
    "    final = data_hoje\n",
    "    inicial = datetime.now() - timedelta(days = 252)\n",
    "    \n",
    "else:\n",
    "    final = data_hoje - timedelta(days = 1)\n",
    "    inicial = datetime.now() - timedelta(days = 252)\n",
    "\n",
    "\n",
    "cotacoes = yf.download(acao, inicial, final)\n",
    "ultimos_60_dias = cotacoes['Close'].iloc[-60:].values.reshape(-1, 1)\n",
    "\n",
    "ultimos_60_dias_escalado = escalador.transform(ultimos_60_dias)\n",
    "\n",
    "teste_x = []\n",
    "teste_x.append(ultimos_60_dias_escalado)\n",
    "teste_x = np.array(teste_x)\n",
    "teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)\n",
    "\n",
    "previsao_de_preco = modelo.predict(teste_x)\n",
    "previsao_de_preco = escalador.inverse_transform(previsao_de_preco)\n",
    "\n",
    "print(f'O modelo prevê o preço para o ativo {acao} de {previsao_de_preco}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a724e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
